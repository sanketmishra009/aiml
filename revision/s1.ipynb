{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "447941a6",
   "metadata": {},
   "source": [
    "# Linear regression:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a88e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iters=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # 1. Setup dimensions\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # 2. Initialize weights to 0\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        # 3. Gradient Descent Loop\n",
    "        for _ in range(self.n_iters):\n",
    "\n",
    "            # Step A: Predict (y = wx + b)\n",
    "            y_predicted = np.dot(X, self.weights) + self.bias\n",
    "\n",
    "            # Step B: Calculate Gradients (Direction to move)\n",
    "            # dw = (1/N) * X.T * (pred - real)\n",
    "            loss = y_predicted - y \n",
    "            dw = (1 / n_samples) * (np.dot(X.T, (y_predicted - y)) + 2 * self.l2_constant * np.sum(self.weights))\n",
    "            # db = (1/N) * sum(pred - real)\n",
    "            db = (1 / n_samples) * np.sum(y_predicted - y)\n",
    "\n",
    "            # Step C: Update Parameters\n",
    "            self.weights = self.weights - self.lr * dw\n",
    "            self.bias = self.bias - self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "\n",
    "# --- Usage Example ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Data: Number of hours studied vs Exam Score\n",
    "    # X needs to be a 2D array (samples, features)\n",
    "    X = np.array([[1], [2], [3], [4], [5]])\n",
    "    y = np.array([2, 4, 6, 8, 10]) # The pattern is y = 2x\n",
    "\n",
    "    model = LinearRegression(learning_rate=0.01, n_iters=1000)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Predict score for studying 6 hours\n",
    "    test_X = np.array([[6]])\n",
    "    prediction = model.predict(test_X)\n",
    "\n",
    "    print(f\"Prediction for 6 hours: {prediction[0]:.2f}\") # Should be close to 12\n",
    "    print(f\"Equation: y = {model.weights[0]:.2f}x + {model.bias:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34fb61de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(5).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c7999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN code\n",
    "#convert to class\n",
    "#run for multiple test dataset:\n",
    "class oknn():\n",
    "    # def __init__(self):\n",
    "    def knn(X,Y,queryPoints,k):\n",
    "        # Euclidean Distance\n",
    "\n",
    "        for query in queryPoints:\n",
    "            queryPoint = query\n",
    "            dist = np.sqrt(np.sum((queryPoint-X)**2,axis=1) )\n",
    "\n",
    "\n",
    "\n",
    "            # Storing distance and Class labels together\n",
    "\n",
    "            distances = [(dist[i],Y[i]) for i in range(len(dist)) ]\n",
    "\n",
    "            # sort the distances\n",
    "            #(2.1,1), ((1.6,1)), (4.5,0)\n",
    "            distances = sorted(distances)\n",
    "\n",
    "            # Nearest/First K points\n",
    "\n",
    "            distances = distances[:k]\n",
    "\n",
    "\n",
    "\n",
    "            distances = np.array(distances)\n",
    "\n",
    "            classes_counts = np.unique(distances[:,1],return_counts=True)\n",
    "\n",
    "\n",
    "\n",
    "            index = classes_counts[1].argmax()\n",
    "\n",
    "            pred = classes_counts[0][index]\n",
    "\n",
    "\n",
    "\n",
    "            return int(pred),distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c74adf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]]),\n",
       " array([10, 35]),\n",
       " array([ 5,  7,  9, 11, 13]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(10).reshape(2, 5)\n",
    "x , x.sum(axis = 1) , x.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a79429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class KNNClassifier:\n",
    "    def __init__(self, k=3):\n",
    "        \"\"\"\n",
    "        Initialize the KNN model.\n",
    "        :param k: The number of neighbors to consider (hyperparameter).\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Store the training data.\n",
    "        Since KNN is a 'lazy learner', this doesn't learn weights,\n",
    "        it just memorizes the data.\n",
    "        \"\"\"\n",
    "        self.X_train = np.array(X)\n",
    "        self.y_train = np.array(y)\n",
    "        print(f\"Model fitted with {len(self.X_train)} training samples.\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Predict class labels for one or more query points.\n",
    "        :param X_test: A list or array of query points.\n",
    "        :return: Array of predicted labels.\n",
    "        \"\"\"\n",
    "        X_test = np.array(X_test)\n",
    "\n",
    "        # If X_test is a single point (1D array), make it 2D so loop works\n",
    "        if X_test.ndim == 1:\n",
    "            X_test = X_test.reshape(1, -1)\n",
    "\n",
    "        # Loop through every point in the test set and predict\n",
    "        predictions = [self._predict_single_point(x) for x in X_test]\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict_single_point(self, query_point):\n",
    "        \"\"\"\n",
    "        Internal helper function to run the logic for a single point.\n",
    "        (This contains the core logic from your original script).\n",
    "        \"\"\"\n",
    "        # 1. Euclidean Distance\n",
    "        # (query_point - all_training_points)\n",
    "        distances = np.sqrt(np.sum((query_point - self.X_train)**2, axis=1))\n",
    "\n",
    "        # 2. Storing distance and Class labels together\n",
    "        # We zip the distances with the training labels\n",
    "        dist_label_pairs = list(zip(distances, self.y_train))\n",
    "\n",
    "        # 3. Sort by distance (first item in tuple)\n",
    "        sorted_pairs = sorted(dist_label_pairs)\n",
    "\n",
    "        # 4. Nearest K points\n",
    "        k_nearest_pairs = sorted_pairs[:self.k]\n",
    "\n",
    "        \n",
    "\n",
    "        # 5. Extract just the labels from those K pairs\n",
    "        k_nearest_labels = [label for dist, label in k_nearest_pairs]\n",
    "\n",
    "        # 6. Majority Vote (using NumPy unique)\n",
    "        classes, counts = np.unique(k_nearest_labels, return_counts=True)\n",
    "\n",
    "        # Find index of max count\n",
    "        max_count_index = counts.argmax()\n",
    "\n",
    "        # Return the winning class\n",
    "        return classes[max_count_index]\n",
    "\n",
    "# --- Usage Example ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Define Dataset (Redness, Roundness) -> 0:Apple, 1:Banana\n",
    "    X_train = [[1, 1], [1, 2], [2, 1], [5, 5], [5, 6], [6, 5]]\n",
    "    y_train = [0, 0, 0, 1, 1, 1]\n",
    "\n",
    "    # 2. Initialize Model\n",
    "    model = KNNClassifier(k=3)\n",
    "\n",
    "    # 3. Fit Model (Load data)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 4. Predict\n",
    "    # Let's test a point that is [2, 2] (should be Apple/0)\n",
    "    # and a point that is [6, 6] (should be Banana/1)\n",
    "    query_points = [[2, 2], [6, 6]]\n",
    "\n",
    "    predictions = model.predict(query_points)\n",
    "\n",
    "    print(f\"\\nTest Points: {query_points}\")\n",
    "    print(f\"Predictions: {predictions}\") # Expected: [0 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230bb5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distance weighted knn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "class KNNClassifier:\n",
    "    def __init__(self, k=3):\n",
    "        \"\"\"\n",
    "        Initialize the KNN model.\n",
    "        :param k: The number of neighbors to consider (hyperparameter).\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Store the training data.\n",
    "        Since KNN is a 'lazy learner', this doesn't learn weights,\n",
    "        it just memorizes the data.\n",
    "        \"\"\"\n",
    "        self.X_train = np.array(X)\n",
    "        self.y_train = np.array(y)\n",
    "        print(f\"Model fitted with {len(self.X_train)} training samples.\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Predict class labels for one or more query points.\n",
    "        :param X_test: A list or array of query points.\n",
    "        :return: Array of predicted labels.\n",
    "        \"\"\"\n",
    "        X_test = np.array(X_test)\n",
    "\n",
    "        # If X_test is a single point (1D array), make it 2D so loop works\n",
    "        if X_test.ndim == 1:\n",
    "            X_test = X_test.reshape(1, -1)\n",
    "\n",
    "        # Loop through every point in the test set and predict\n",
    "        predictions = [self._predict_single_point(x) for x in X_test]\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "break    def _predict_single_point(self, query_point):\n",
    "        \"\"\"\n",
    "        Internal helper function to run the logic for a single point.\n",
    "        (This contains the core logic from your original script).\n",
    "        \"\"\"\n",
    "        # 1. Euclidean Distance\n",
    "        # (query_point - all_training_points)\n",
    "        distances = np.sqrt(np.sum((query_point - self.X_train)**2, axis=1))\n",
    "\n",
    "        # 2. Storing distance and Class labels together\n",
    "        # We zip the distances with the training labels\n",
    "        dist_label_pairs = list(zip(distances, self.y_train))\n",
    "\n",
    "        # 3. Sort by distance (first item in tuple)\n",
    "        sorted_pairs = sorted(dist_label_pairs)\n",
    "\n",
    "        # 4. Nearest K points\n",
    "        k_nearest_pairs = sorted_pairs[:self.k]\n",
    "        df = pd.DataFrame(k_nearest_pairs , columns = ['distance' , 'class'])\n",
    "        gdf = df.groupby('class').agg({'distance' : np.sum})\n",
    "        gdf = gdf.sort_values(by = ['distance'])\n",
    "\n",
    "\n",
    "        return gdf.iloc[0]['class']\n",
    "\n",
    "# --- Usage Example ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Define Dataset (Redness, Roundness) -> 0:Apple, 1:Banana\n",
    "    X_train = [[1, 1], [1, 2], [2, 1], [5, 5], [5, 6], [6, 5]]\n",
    "    y_train = [0, 0, 0, 1, 1, 1]\n",
    "\n",
    "    # 2. Initialize Model\n",
    "    model = KNNClassifier(k=3)\n",
    "\n",
    "    # 3. Fit Model (Load data)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 4. Predict\n",
    "    # Let's test a point that is [2, 2] (should be Apple/0)\n",
    "    # and a point that is [6, 6] (should be Banana/1)\n",
    "    query_points = [[2, 2], [6, 6]]\n",
    "\n",
    "    predictions = model.predict(query_points)\n",
    "\n",
    "    print(f\"\\nTest Points: {query_points}\")\n",
    "    print(f\"Predictions: {predictions}\") # Expected: [0 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ec507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#Logistic Regression:\n",
    "class LogisticR():\n",
    "    def __init__(self , lr , niter):\n",
    "        self.lr = lr\n",
    "        self.niter = niter\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self , x , y):\n",
    "        n , m = x.shape\n",
    "        self.weights = np.zeros(m)\n",
    "        self.bias = 0\n",
    "\n",
    "        for i in range(self.lr):\n",
    "            z = np.matmul(self.weights , x)\n",
    "            logits = tf.nn.sigmoid(z)\n",
    "\n",
    "            dlogloss = logits * (1 - logits)\n",
    "\n",
    "            self.weights += self.lr * dlogloss\n",
    "\n",
    "        return self.weights\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self , x):\n",
    "        return tf.nn.sigmoid(np.matmul())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08d08a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(5).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83caeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision tree:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
