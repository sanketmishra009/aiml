{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27eb3aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color = sns.color_palette('dark'))\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43473020",
   "metadata": {},
   "source": [
    "## Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ef7e858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloasd dataset\n",
    "\n",
    "\n",
    "# !gdown https://drive.google.com/file/d/1DNgciEZTQWuo_wq4qMGIV8z3VC1Onjjv/view?usp=share_link --fuzzy --output ../../data/nlp/attention_data/\n",
    "# !gdown https://drive.google.com/file/d/1ePfUhb2XeicnybAMu0y2w3BhiWm4XY8t/view?usp=share_link --fuzzy --output ../../data/nlp/attention_data/\n",
    "# !gdown https://drive.google.com/file/d/1FRn6Gn3ijmCWfhUI6QkGm4g4LeQ7Veg0/view?usp=share_link --fuzzy --output ../../data/nlp/attention_data/\n",
    "# !gdown https://drive.google.com/file/d/1Fw3yivW_PSH-C5T_4-9bWshxPHxvxtAi/view?usp=share_link --fuzzy --output ../../data/nlp/attention_data/\n",
    "# !gdown https://drive.google.com/file/d/1F9r26d7emj43EG6kcMfvOsu1rI8yxR4d/view?usp=share_link --fuzzy --output ../../data/nlp/attention_data/\n",
    "# !gdown https://drive.google.com/file/d/1zSYr8akNxtCCR_TxVIFrel1k254k-vin/view?usp=share_link --fuzzy --output ../../data/nlp/attention_data/\n",
    "# !gdown https://drive.google.com/file/d/1zSYr8akNxtCCR_TxVIFrel1k254k-vin/view?usp=share_link --fuzzy --output ../../data/nlp/attention_data/\n",
    "# !gdown https://drive.google.com/file/d/1zSYr8akNxtCCR_TxVIFrel1k254k-vin/view?usp=share_link --fuzzy --output ../../data/nlp/attention_data/\n",
    "# !gdown https://drive.google.com/file/d/1I0vjwcnwfaMZdwhS-oJjqUoihl9NxZ1g/view?usp=share_link --fuzzy --output ../../data/nlp/attention_data/\n",
    "# !gdown https://drive.google.com/file/d/1tX9mZBStZGCQmOhgaCu-tSdlXqQU77ou/view?usp=share_link --fuzzy --output ../../data/nlp/attention_data/\n",
    "# !gdown https://drive.google.com/file/d/1-GNcBpiB3Y0RzbJLawxL31IjkTBtpUz2/view?usp=share_link --fuzzy --output ../../data/nlp/attention_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23fc2bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mams_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[['text' , 'term' , 'polarity']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00f5b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laptop_dev.csv   mams_test.csv    rest16_dev.csv\n",
      "laptop_test.csv  mams_train.csv   rest16_test.csv\n",
      "laptop_train.csv mams_val.csv     rest16_train.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ../../data/nlp/attention_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "413e8558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11186, 3), (1336, 3), (1332, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "basedir = '../../data/nlp/attention_data'\n",
    "# list file names starting with mams:\n",
    "files = os.listdir(f'{basedir}')\n",
    "mams_files = [f\"{basedir}/{file}\" for file in files if file.startswith('mams')]\n",
    "mamsval , mamstest , mamstrain = list(map(load_mams_data , mams_files))\n",
    "mamstrain.shape , mamstest.shape , mamsval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b763d817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1916, 3), (577, 3), (246, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load laptop data\n",
    "def load_laptop_data(path):\n",
    "    textds = []\n",
    "    termds = []\n",
    "    polarityds = []\n",
    "\n",
    "    with open(path , 'r') as file:\n",
    "        data = file.read().splitlines()\n",
    "\n",
    "\n",
    "    terms = []\n",
    "    polarities = []\n",
    "    text = ''\n",
    "    polarity = ''\n",
    "    term = ''\n",
    "\n",
    "    for row in data[2:]:\n",
    "        if len(row) == 1:\n",
    "            if term != '':\n",
    "                terms.append(term)\n",
    "                polarities.append(polarity)\n",
    "            for i in range(len(terms)):\n",
    "                textds.append(text.strip())\n",
    "                polarityds.append(polarities[i])\n",
    "                termds.append(terms[i].strip())\n",
    "            \n",
    "            text = ''\n",
    "            polarity = ''\n",
    "            term = ''\n",
    "            terms = []\n",
    "            polarities = []\n",
    "\n",
    "        else:\n",
    "            token , label = row.split(',' , 1)\n",
    "            text += ' ' + token\n",
    "\n",
    "            if label == 'T-POS':\n",
    "                label = 'positive'\n",
    "            elif label == 'T-NEG':\n",
    "                label = 'negative'\n",
    "            elif label == 'T-NEU':\n",
    "                label = 'neutral'\n",
    "            else:\n",
    "                if term != '':\n",
    "                    terms.append(term)\n",
    "                    polarities.append(polarity)\n",
    "\n",
    "                term = ''\n",
    "                polarity = ''\n",
    "                continue\n",
    "\n",
    "            if polarity == label:\n",
    "                term += ' ' + token\n",
    "\n",
    "            else:\n",
    "                if term != '':\n",
    "                    terms.append(term)\n",
    "                    polarities.append(polarity)\n",
    "\n",
    "                polarity = label\n",
    "                term = token\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['text'] = textds\n",
    "    df['term'] = termds\n",
    "    df['polarity'] = polarityds\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "laptop_files = [f'{basedir}/{file}' for file in files if file.startswith('laptop')]\n",
    "lapval , laptest , laptrain = list(map(load_laptop_data , laptop_files))\n",
    "laptrain.shape , laptest.shape , lapval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2a08393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1501, 3), (585, 3), (159, 3))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load restaurant data:\n",
    "restFiles = [f'{basedir}/{file}' for file in files if file.startswith('rest')]\n",
    "restval , resttrain , resttest = list(map(load_laptop_data , restFiles))\n",
    "resttrain.shape , resttest.shape , restval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f92dc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.concat([mamstrain , laptrain , resttrain , mamstest , resttest , laptest]).sample(frac = 1).reset_index(drop = True)\n",
    "valdf = pd.concat([mamsval , lapval , restval]).sample(frac = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0951a8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** data ******************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>term</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Though the picture \" video \" and music softwar...</td>\n",
       "      <td>picture</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We asked for the manager who told us that it w...</td>\n",
       "      <td>manager</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Our server (after 4 reminders) finally got aro...</td>\n",
       "      <td>meal</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food and beer make up for it, but it would...</td>\n",
       "      <td>beer</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>One more tip \" please purchase this model and ...</td>\n",
       "      <td>4GB stick of RAM</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              term  \\\n",
       "0  Though the picture \" video \" and music softwar...           picture   \n",
       "1  We asked for the manager who told us that it w...           manager   \n",
       "2  Our server (after 4 reminders) finally got aro...              meal   \n",
       "3  The food and beer make up for it, but it would...              beer   \n",
       "4  One more tip \" please purchase this model and ...  4GB stick of RAM   \n",
       "\n",
       "   polarity  \n",
       "0  negative  \n",
       "1  positive  \n",
       "2   neutral  \n",
       "3  positive  \n",
       "4  positive  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('*'*30 , 'data' , '*' *30)\n",
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "defe90b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** data uniqueness ******************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "text        7838\n",
       "term        4488\n",
       "polarity       3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('*'*30 , 'data uniqueness' , '*' *30)\n",
    "traindf.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ca2f17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** Sentiment labels ******************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "polarity\n",
       "positive    6456\n",
       "neutral     6270\n",
       "negative    4375\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('*'*30 , 'Sentiment labels' , '*' *30)\n",
    "traindf.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54a76bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>term</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>though the picture \" video \" and music softwar...</td>\n",
       "      <td>picture</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we asked for the manager who told us that it w...</td>\n",
       "      <td>manager</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the food and beer make up for it, but it would...</td>\n",
       "      <td>beer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one more tip \" please purchase this model and ...</td>\n",
       "      <td>4gb stick of ram</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>calle ocho is definitely high on my list, the ...</td>\n",
       "      <td>mojitos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              term  \\\n",
       "0  though the picture \" video \" and music softwar...           picture   \n",
       "1  we asked for the manager who told us that it w...           manager   \n",
       "3  the food and beer make up for it, but it would...              beer   \n",
       "4  one more tip \" please purchase this model and ...  4gb stick of ram   \n",
       "5  calle ocho is definitely high on my list, the ...           mojitos   \n",
       "\n",
       "   polarity  \n",
       "0         0  \n",
       "1         1  \n",
       "3         1  \n",
       "4         1  \n",
       "5         1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#consider only positive and negative polarities and convert them to int indexes:\n",
    "traindf = traindf[traindf['polarity'] != 'neutral']\n",
    "valdf = valdf[valdf['polarity'] != 'neutral']\n",
    "\n",
    "pol2id = {'positive' : 1 , 'negative' : 0}\n",
    "\n",
    "for data in [traindf , valdf]:\n",
    "    data['polarity'] = data['polarity'].apply(lambda x: pol2id[x])\n",
    "    data['text'] = data['text'].apply(lambda x : x.lower())\n",
    "    data['term'] = data['term'].apply(lambda x : x.lower())\n",
    "\n",
    "    data = data.drop_duplicates(['text' , 'term' , 'polarity'])\n",
    "traindf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881ebf3f",
   "metadata": {},
   "source": [
    "## Tokenize and embedding and train-test split:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bab7ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load embedding model and convert to embeddings:\n",
    "import gensim.downloader as api\n",
    "\n",
    "embedding_size = 300\n",
    "\n",
    "word2vec = api.load('word2vec-google-news-300')\n",
    "\n",
    "#tokenize the text\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(lower = True)\n",
    "tokenizer.fit_on_texts(traindf['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfafca9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted 9019 words and missed 1234 words\n"
     ]
    }
   ],
   "source": [
    "# create embedding matrix:\n",
    "ttokens = len(tokenizer.word_index) + 1\n",
    "embeddings = np.zeros((ttokens , embedding_size))\n",
    "\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "for word , i in tokenizer.word_index.items():\n",
    "    embedding = None\n",
    "    try:\n",
    "        embedding = word2vec[word]\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    if embedding is not None:\n",
    "        embeddings[i] = embedding\n",
    "        hits+=1\n",
    "    else: misses += 1\n",
    "\n",
    "del word2vec\n",
    "print(f\"converted {hits} words and missed {misses} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d61bbc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize and pad:\n",
    "def toknpad(text , seqlen):\n",
    "    tokens = tokenizer.texts_to_sequences([text])\n",
    "    paddedTokens = tf.keras.preprocessing.sequence.pad_sequences(tokens , maxlen = seqlen)\n",
    "    return paddedTokens[0]\n",
    "\n",
    "def prepare_tokenize(dataset):\n",
    "    texts = []\n",
    "    terms = []\n",
    "    polarities = []\n",
    "\n",
    "    for id , row in dataset.iterrows():\n",
    "        texts.append(toknpad(row['text'] , 128))\n",
    "        terms.append(toknpad(row['term'] , 4))\n",
    "        polarities.append(row['polarity'])\n",
    "\n",
    "    texts = tf.constant(texts)\n",
    "    terms = tf.constant(terms)\n",
    "    polarities = tf.constant(polarities)\n",
    "\n",
    "    return (texts , terms , polarities)\n",
    "\n",
    "ttexts , tterms , tpolarities = prepare_tokenize(traindf)\n",
    "vtexts , vterms , vpolarities = prepare_tokenize(valdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b32545f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "Review text tf.Tensor(\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0  117    1 2059  833    2  278  321    7 1704  574    4 1096 2224\n",
      "  321 2225  384    4 3429   13  210    1 1097    9 3430    2   55 2992\n",
      " 1534 3431], shape=(128,), dtype=int32)\n",
      "****************************************************************\n",
      "Aspect text tf.Tensor([   0    0    0 2059], shape=(4,), dtype=int32)\n",
      "****************************************************************\n",
      "Polarity tf.Tensor(0, shape=(), dtype=int32)\n",
      "****************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"*\"*64)\n",
    "print(\"Review text\", ttexts[0])\n",
    "print(\"*\"*64)\n",
    "print(\"Aspect text\", tterms[0])\n",
    "print(\"*\"*64)\n",
    "print(\"Polarity\", tpolarities[0])\n",
    "print(\"*\"*64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d149912e",
   "metadata": {},
   "source": [
    "## model implementation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6bdd742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, name=\"simple_attention\"):\n",
    "        super(Attention, self).__init__(name=name)\n",
    "        self.units = units\n",
    "        self.Wk = tf.keras.layers.Dense(units)\n",
    "        self.Wq = tf.keras.layers.Dense(units)\n",
    "        self.Wv = tf.keras.layers.Dense(units)\n",
    "\n",
    "    def call(self, keys, queries):\n",
    "        \"\"\"\n",
    "        keys:    (batch, R, dim)  -> review encoder output\n",
    "        queries: (batch, A, dim)  -> aspect encoder output\n",
    "        \"\"\"\n",
    "\n",
    "        # Linear projections\n",
    "        K = self.Wk(keys)       # (batch, R, units)\n",
    "        Q = self.Wq(queries)    # (batch, A, units)\n",
    "        V = self.Wv(keys)       # (batch, R, units)\n",
    "\n",
    "        # Compute raw scores\n",
    "        scores = tf.matmul(K , Q , transpose_b=True)   # (batch, k , q)\n",
    "\n",
    "        # Softmax over key dimension (review length R)\n",
    "        attn = tf.nn.softmax(scores, axis=-1)        # (batch, l , q)\n",
    "\n",
    "        print(f\"{attn.shape=}\")\n",
    "        # Weighted sum to get context\n",
    "\n",
    "\n",
    "        attnexp = tf.expand_dims(attn , axis = -1)\n",
    "        vexp = tf.expand_dims(V , axis = 2)\n",
    "\n",
    "        print(f\"{attnexp.shape=} , {vexp.shape=}\")\n",
    "\n",
    "        context = attnexp * vexp\n",
    "        \n",
    "        print(f\"{context.shape=}\")\n",
    "        out = tf.reduce_sum(context , axis = [2,3] , keepdims = True)\n",
    "        out = tf.squeeze(out , axis = [2,3])\n",
    "\n",
    "\n",
    "        # If aspect_len = 1 → squeeze to (batch, units)\n",
    "        # if context.shape[1] == 1:\n",
    "        #     context = tf.squeeze(context, axis=1)    # (batch, units)\n",
    "        #     attn = tf.squeeze(attn, axis=1)          # (batch, R)\n",
    "\n",
    "\n",
    "        print(f\"{out.shape=}\")\n",
    "        return out, attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ebbe9454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn.shape=TensorShape([None, 128, 4])\n",
      "attnexp.shape=TensorShape([None, 128, 4, 1]) , vexp.shape=TensorShape([None, 128, 1, 256])\n",
      "context.shape=TensorShape([None, 128, 4, 256])\n",
      "out.shape=TensorShape([None, 128])\n",
      "attn.shape=TensorShape([None, 128, 4])\n",
      "attnexp.shape=TensorShape([None, 128, 4, 1]) , vexp.shape=TensorShape([None, 128, 1, 256])\n",
      "context.shape=TensorShape([None, 128, 4, 256])\n",
      "out.shape=TensorShape([None, 128])\n",
      "values.shape=(None, 128)\n",
      "output.shape=(None, 1)\n",
      "Epoch 1/5\n",
      "attn.shape=TensorShape([None, 128, 4])\n",
      "attnexp.shape=TensorShape([None, 128, 4, 1]) , vexp.shape=TensorShape([None, 128, 1, 256])\n",
      "context.shape=TensorShape([None, 128, 4, 256])\n",
      "out.shape=TensorShape([None, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/src/layers/layer.py:965: UserWarning: Layer 'simple_attention' (of type Attention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn.shape=TensorShape([None, 128, 4])\n",
      "attnexp.shape=TensorShape([None, 128, 4, 1]) , vexp.shape=TensorShape([None, 128, 1, 256])\n",
      "context.shape=TensorShape([None, 128, 4, 256])\n",
      "out.shape=TensorShape([None, 128])\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 210ms/step - accuracy: 0.5971 - loss: 1.6470\n",
      "Epoch 2/5\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 228ms/step - accuracy: 0.7796 - loss: 0.4568\n",
      "Epoch 3/5\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 235ms/step - accuracy: 0.8002 - loss: 0.4220\n",
      "Epoch 4/5\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 236ms/step - accuracy: 0.8192 - loss: 0.3886\n",
      "Epoch 5/5\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 247ms/step - accuracy: 0.8286 - loss: 0.3698\n"
     ]
    }
   ],
   "source": [
    "#create a functional model:\n",
    "\n",
    "review_input = tf.keras.layers.Input(shape = (128 , ) , dtype = 'int32' , name = 'review_input')\n",
    "aspect_input = tf.keras.layers.Input(shape = (4 ,) , dtype = 'int32' , name = 'aspect_input')\n",
    "\n",
    "#get embeddings (same embedding matrix for review and aspect):\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim = ttokens , output_dim= embedding_size , embeddings_initializer= tf.keras.initializers.Constant(embeddings) , mask_zero = True , name = 'shared_embedding_layer')\n",
    "\n",
    "rembeddings = embedding_layer(review_input)\n",
    "aembeddings = embedding_layer(aspect_input)\n",
    "\n",
    "rmask = embedding_layer.compute_mask(review_input)\n",
    "amask = embedding_layer.compute_mask(aspect_input)\n",
    "\n",
    "\n",
    "#get key , query and value vectors:\n",
    "\n",
    "rencoder = tf.keras.layers.GRU(256 , return_sequences= True , name = 'review_encoder')\n",
    "aencoder = tf.keras.layers.GRU(256 , return_sequences= True , name = 'aspect_encoder')\n",
    "\n",
    "\n",
    "rkeys = rencoder(rembeddings)\n",
    "akeys = aencoder(aembeddings)\n",
    "\n",
    "#get attention vector:\n",
    "\n",
    "attention_layer = Attention(256)\n",
    "\n",
    "values , attention_weights = attention_layer(rkeys , akeys)\n",
    "\n",
    "print(f\"{values.shape=}\")\n",
    "#compute sentiment:\n",
    "\n",
    "values = tf.keras.layers.Dense(64 , activation = 'relu' , name = 'penultimate_layer')(values)\n",
    "output = tf.keras.layers.Dense(1 , activation = 'sigmoid' , name = 'final_output')(values)\n",
    "print(f\"{output.shape=}\")\n",
    "\n",
    "#create model:\n",
    "\n",
    "model = tf.keras.Model(inputs = [review_input , aspect_input] , outputs = output , name = 'sentiment_model_with_attention')\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "#compile model:\n",
    "learning_rate = tf.keras.optimizers.schedules.PolynomialDecay(1e-2, 236, 1e-4)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate),\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "#train:\n",
    "history = model.fit(\n",
    "    x = [ttexts , tterms],\n",
    "    y = tpolarities,\n",
    "    batch_size = 32,\n",
    "    epochs = 5,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7780121b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after reshape: (10831, 1) (1084, 1)\n"
     ]
    }
   ],
   "source": [
    "# ensure shapes are (N,1) and float32\n",
    "tpolarities = np.asarray(tpolarities).reshape(-1,1).astype('float32')\n",
    "vpolarities = np.asarray(vpolarities).reshape(-1,1).astype('float32')\n",
    "print(\"after reshape:\", tpolarities.shape, vpolarities.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "443e4f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([10831, 128]), TensorShape([10831, 4]), (10831, 1))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttexts.shape , tterms.shape , tpolarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cc659318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "attention_computation begin.\n",
      "keymask.shape=TensorShape([None, 128, 1]) , querymask.shape=TensorShape([None, 1, 4]) , scores.shape=TensorShape([None, 128, 4])\n",
      "attention_computation done.\n",
      "cvector.shape=TensorShape([None, 128])\n",
      "attention_computation begin.\n",
      "keymask.shape=TensorShape([None, 128, 1]) , querymask.shape=TensorShape([None, 1, 4]) , scores.shape=TensorShape([None, 128, 4])\n",
      "attention_computation done.\n",
      "cvector.shape=TensorShape([None, 128])\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node gradient_tape/compile_loss/binary_crossentropy/mul_1/BroadcastGradientArgs defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/var/folders/5f/scjcfk_97_n7zmjltnpm2mjc0000gn/T/ipykernel_1573/3594099813.py\", line 1, in <module>\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 78, in train_step\n\nIncompatible shapes: [32] vs. [32,128]\n\t [[{{node gradient_tape/compile_loss/binary_crossentropy/mul_1/BroadcastGradientArgs}}]] [Op:__inference_multi_step_on_iterator_71579]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mttexts\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtterms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtpolarities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node gradient_tape/compile_loss/binary_crossentropy/mul_1/BroadcastGradientArgs defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/var/folders/5f/scjcfk_97_n7zmjltnpm2mjc0000gn/T/ipykernel_1573/3594099813.py\", line 1, in <module>\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 78, in train_step\n\nIncompatible shapes: [32] vs. [32,128]\n\t [[{{node gradient_tape/compile_loss/binary_crossentropy/mul_1/BroadcastGradientArgs}}]] [Op:__inference_multi_step_on_iterator_71579]"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = [ttexts , tterms],\n",
    "    y = tpolarities,\n",
    "    batch_size = 32,\n",
    "    epochs = 5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbce0bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10831, 128) (10831, 4) (10831, 1)\n",
      "(1084, 128) (1084, 4) (1084, 1)\n"
     ]
    }
   ],
   "source": [
    "# if using numpy arrays / tf.data\n",
    "print(ttexts.shape, tterms.shape, tpolarities.shape)   # shapes you pass as x,y\n",
    "# or if validation_data tuple:\n",
    "print(vtexts.shape, vterms.shape, vpolarities.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33e6090d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after reshape: (10831, 1) (1084, 1)\n"
     ]
    }
   ],
   "source": [
    "# ensure shapes are (N,1) and float32\n",
    "tpolarities = np.asarray(tpolarities).reshape(-1,1).astype('float32')\n",
    "vpolarities = np.asarray(vpolarities).reshape(-1,1).astype('float32')\n",
    "print(\"after reshape:\", tpolarities.shape, vpolarities.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9726bc11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
