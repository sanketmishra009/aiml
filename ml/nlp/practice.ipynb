{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb338f00",
   "metadata": {},
   "source": [
    "# Notebook for practicing nlp techniques:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3e46a5",
   "metadata": {},
   "source": [
    "# Text pre-processing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bdbc7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Machine learning (ML) is a field of study in artificial intelligence concerned with the development of computer algorithms that can learn from and make predictions on data. Algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task.\n",
      "\n",
      "Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop conventional algorithms to perform the needed tasks. A subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers. Mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning.\n",
      "\n",
      "In its application across business problems, machine learning is also referred to as predictive analytics.\n",
      "\n",
      "Machine learning rocks! It's revolutionizing the world in 2023 (and beyond!).\n",
      "Visit our site: http://example.com for more info.\n",
      "This is awesome!!! We collected 1,234 data points.\n",
      "Softbank and Google are major players.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample text representing a part of a document\n",
    "sample_document = \"\"\"\n",
    "Machine learning (ML) is a field of study in artificial intelligence concerned with the development of computer algorithms that can learn from and make predictions on data. Algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task.\n",
    "\n",
    "Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop conventional algorithms to perform the needed tasks. A subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers. Mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning.\n",
    "\n",
    "In its application across business problems, machine learning is also referred to as predictive analytics.\n",
    "\"\"\"\n",
    "\n",
    "# Let's also add some text with punctuation, numbers, and mixed casing\n",
    "noisy_text = \"\"\"\n",
    "Machine learning rocks! It's revolutionizing the world in 2023 (and beyond!).\n",
    "Visit our site: http://example.com for more info.\n",
    "This is awesome!!! We collected 1,234 data points.\n",
    "Softbank and Google are major players.\n",
    "\"\"\"\n",
    "\n",
    "rdata = sample_document + noisy_text\n",
    "print(rdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c31c0e",
   "metadata": {},
   "source": [
    "## Convert to lowercase:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b40de1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowered Data: \n",
      "machine learning (ml) is a field of study in artificial intelligence concerned with the development of computer algorithms that can learn from and make predictions on data. algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task.\n",
      "\n",
      "machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop conventional algorithms to perform the needed tasks. a subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers. mathematical optimization delivers methods, theory and application domains to the field of machine learning. data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning.\n",
      "\n",
      "in its application across business problems, machine learning is also referred to as predictive analytics.\n",
      "\n",
      "machine learning rocks! it's revolutionizing the world in 2023 (and beyond!).\n",
      "visit our site: http://example.com for more info.\n",
      "this is awesome!!! we collected 1,234 data points.\n",
      "softbank and google are major players.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# str.lower(rdata)\n",
    "lowdata = rdata.lower()\n",
    "print(f'Lowered Data: {lowdata}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e682731",
   "metadata": {},
   "source": [
    "## Remove urls using regex:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16b0df3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "machine learning (ml) is a field of study in artificial intelligence concerned with the development of computer algorithms that can learn from and make predictions on data. algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task.\n",
      "\n",
      "machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop conventional algorithms to perform the needed tasks. a subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers. mathematical optimization delivers methods, theory and application domains to the field of machine learning. data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning.\n",
      "\n",
      "in its application across business problems, machine learning is also referred to as predictive analytics.\n",
      "\n",
      "machine learning rocks! it's revolutionizing the world in 2023 (and beyond!).\n",
      "visit our site:  for more info.\n",
      "this is awesome!!! we collected 1,234 data points.\n",
      "softbank and google are major players.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern = r\"(https?://| www\\.)\\S+\"\n",
    "nurldata = re.sub(pattern , '' , lowdata)\n",
    "print(nurldata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c9a16a",
   "metadata": {},
   "source": [
    "## Remove punctuations:\n",
    "\n",
    "- string.maketrans()\n",
    "- string.translate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e9a56fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "machine learning ml is a field of study in artificial intelligence concerned with the development of computer algorithms that can learn from and make predictions on data algorithms build a mathematical model based on sample data known as training data in order to make predictions or decisions without being explicitly programmed to perform the task\n",
      "\n",
      "machine learning algorithms are used in a wide variety of applications such as email filtering and computer vision where it is difficult or infeasible to develop conventional algorithms to perform the needed tasks a subset of machine learning is closely related to computational statistics which focuses on making predictions using computers mathematical optimization delivers methods theory and application domains to the field of machine learning data mining is a related field of study focusing on exploratory data analysis through unsupervised learning\n",
      "\n",
      "in its application across business problems machine learning is also referred to as predictive analytics\n",
      "\n",
      "machine learning rocks its revolutionizing the world in 2023 and beyond\n",
      "visit our site  for more info\n",
      "this is awesome we collected 1234 data points\n",
      "softbank and google are major players\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "transtable = str.maketrans('' , '' , string.punctuation)\n",
    "npunctdata = str.translate(nurldata , transtable)\n",
    "print(npunctdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650ae355",
   "metadata": {},
   "source": [
    "## Remove digits and extra whitespaces:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8d1b1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " machine learning ml is a field of study in artificial intelligence concerned with the development of computer algorithms that can learn from and make predictions on data algorithms build a mathematical model based on sample data known as training data in order to make predictions or decisions without being explicitly programmed to perform the task machine learning algorithms are used in a wide variety of applications such as email filtering and computer vision where it is difficult or infeasible to develop conventional algorithms to perform the needed tasks a subset of machine learning is closely related to computational statistics which focuses on making predictions using computers mathematical optimization delivers methods theory and application domains to the field of machine learning data mining is a related field of study focusing on exploratory data analysis through unsupervised learning in its application across business problems machine learning is also referred to as predictive analytics machine learning rocks its revolutionizing the world in and beyond visit our site for more info this is awesome we collected data points softbank and google are major players \n"
     ]
    }
   ],
   "source": [
    "def clean(data):\n",
    "    data = re.sub('\\d+' , '' , data)\n",
    "    data = re.sub('\\s+' , ' ' , data)\n",
    "    return data\n",
    "cdata = clean(npunctdata)\n",
    "print(cdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e3b05a",
   "metadata": {},
   "source": [
    "## Tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0939c203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: \n",
      "Machine learning (ML) is a field of study in artificial intelligence concerned with the development of computer algorithms that can learn from and make predictions on data.\n",
      "Sentence 2: Algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task.\n",
      "Sentence 3: Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop conventional algorithms to perform the needed tasks.\n",
      "Sentence 4: A subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers.\n",
      "Sentence 5: Mathematical optimization delivers methods, theory and application domains to the field of machine learning.\n",
      "Sentence 6: Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning.\n",
      "Sentence 7: In its application across business problems, machine learning is also referred to as predictive analytics.\n",
      "Sentence 8: Machine learning rocks!\n",
      "Sentence 9: It's revolutionizing the world in 2023 (and beyond!).\n",
      "Sentence 10: Visit our site: http://example.com for more info.\n",
      "Sentence 11: This is awesome!!!\n",
      "Sentence 12: We collected 1,234 data points.\n",
      "Sentence 13: Softbank and Google are major players.\n"
     ]
    }
   ],
   "source": [
    "# tokenization using nltk:\n",
    "from nltk.tokenize import sent_tokenize , word_tokenize\n",
    "\n",
    "stokens = sent_tokenize(rdata)\n",
    "for i , sentence in enumerate(stokens):\n",
    "    print(f\"Sentence {i+1}: {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4d36991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word 1: Machine\n",
      "word 2: learning\n",
      "word 3: (\n",
      "word 4: ML\n",
      "word 5: )\n",
      "word 6: is\n",
      "word 7: a\n",
      "word 8: field\n",
      "word 9: of\n",
      "word 10: study\n",
      "word 11: in\n",
      "word 12: artificial\n",
      "word 13: intelligence\n",
      "word 14: concerned\n",
      "word 15: with\n",
      "word 16: the\n",
      "word 17: development\n",
      "word 18: of\n",
      "word 19: computer\n",
      "word 20: algorithms\n",
      "word 21: that\n",
      "word 22: can\n",
      "word 23: learn\n",
      "word 24: from\n",
      "word 25: and\n",
      "word 26: make\n",
      "word 27: predictions\n",
      "word 28: on\n",
      "word 29: data\n",
      "word 30: .\n",
      "word 31: Algorithms\n",
      "word 32: build\n",
      "word 33: a\n",
      "word 34: mathematical\n",
      "word 35: model\n",
      "word 36: based\n",
      "word 37: on\n",
      "word 38: sample\n",
      "word 39: data\n",
      "word 40: ,\n",
      "word 41: known\n",
      "word 42: as\n",
      "word 43: ``\n",
      "word 44: training\n",
      "word 45: data\n",
      "word 46: ''\n",
      "word 47: ,\n",
      "word 48: in\n",
      "word 49: order\n",
      "word 50: to\n",
      "word 51: make\n",
      "word 52: predictions\n",
      "word 53: or\n",
      "word 54: decisions\n",
      "word 55: without\n",
      "word 56: being\n",
      "word 57: explicitly\n",
      "word 58: programmed\n",
      "word 59: to\n",
      "word 60: perform\n",
      "word 61: the\n",
      "word 62: task\n",
      "word 63: .\n",
      "word 64: Machine\n",
      "word 65: learning\n",
      "word 66: algorithms\n",
      "word 67: are\n",
      "word 68: used\n",
      "word 69: in\n",
      "word 70: a\n",
      "word 71: wide\n",
      "word 72: variety\n",
      "word 73: of\n",
      "word 74: applications\n",
      "word 75: ,\n",
      "word 76: such\n",
      "word 77: as\n",
      "word 78: email\n",
      "word 79: filtering\n",
      "word 80: and\n",
      "word 81: computer\n",
      "word 82: vision\n",
      "word 83: ,\n",
      "word 84: where\n",
      "word 85: it\n",
      "word 86: is\n",
      "word 87: difficult\n",
      "word 88: or\n",
      "word 89: infeasible\n",
      "word 90: to\n",
      "word 91: develop\n",
      "word 92: conventional\n",
      "word 93: algorithms\n",
      "word 94: to\n",
      "word 95: perform\n",
      "word 96: the\n",
      "word 97: needed\n",
      "word 98: tasks\n",
      "word 99: .\n",
      "word 100: A\n",
      "word 101: subset\n",
      "word 102: of\n",
      "word 103: machine\n",
      "word 104: learning\n",
      "word 105: is\n",
      "word 106: closely\n",
      "word 107: related\n",
      "word 108: to\n",
      "word 109: computational\n",
      "word 110: statistics\n",
      "word 111: ,\n",
      "word 112: which\n",
      "word 113: focuses\n",
      "word 114: on\n",
      "word 115: making\n",
      "word 116: predictions\n",
      "word 117: using\n",
      "word 118: computers\n",
      "word 119: .\n",
      "word 120: Mathematical\n",
      "word 121: optimization\n",
      "word 122: delivers\n",
      "word 123: methods\n",
      "word 124: ,\n",
      "word 125: theory\n",
      "word 126: and\n",
      "word 127: application\n",
      "word 128: domains\n",
      "word 129: to\n",
      "word 130: the\n",
      "word 131: field\n",
      "word 132: of\n",
      "word 133: machine\n",
      "word 134: learning\n",
      "word 135: .\n",
      "word 136: Data\n",
      "word 137: mining\n",
      "word 138: is\n",
      "word 139: a\n",
      "word 140: related\n",
      "word 141: field\n",
      "word 142: of\n",
      "word 143: study\n",
      "word 144: ,\n",
      "word 145: focusing\n",
      "word 146: on\n",
      "word 147: exploratory\n",
      "word 148: data\n",
      "word 149: analysis\n",
      "word 150: through\n",
      "word 151: unsupervised\n",
      "word 152: learning\n",
      "word 153: .\n",
      "word 154: In\n",
      "word 155: its\n",
      "word 156: application\n",
      "word 157: across\n",
      "word 158: business\n",
      "word 159: problems\n",
      "word 160: ,\n",
      "word 161: machine\n",
      "word 162: learning\n",
      "word 163: is\n",
      "word 164: also\n",
      "word 165: referred\n",
      "word 166: to\n",
      "word 167: as\n",
      "word 168: predictive\n",
      "word 169: analytics\n",
      "word 170: .\n",
      "word 171: Machine\n",
      "word 172: learning\n",
      "word 173: rocks\n",
      "word 174: !\n",
      "word 175: It\n",
      "word 176: 's\n",
      "word 177: revolutionizing\n",
      "word 178: the\n",
      "word 179: world\n",
      "word 180: in\n",
      "word 181: 2023\n",
      "word 182: (\n",
      "word 183: and\n",
      "word 184: beyond\n",
      "word 185: !\n",
      "word 186: )\n",
      "word 187: .\n",
      "word 188: Visit\n",
      "word 189: our\n",
      "word 190: site\n",
      "word 191: :\n",
      "word 192: http\n",
      "word 193: :\n",
      "word 194: //example.com\n",
      "word 195: for\n",
      "word 196: more\n",
      "word 197: info\n",
      "word 198: .\n",
      "word 199: This\n",
      "word 200: is\n",
      "word 201: awesome\n",
      "word 202: !\n",
      "word 203: !\n",
      "word 204: !\n",
      "word 205: We\n",
      "word 206: collected\n",
      "word 207: 1,234\n",
      "word 208: data\n",
      "word 209: points\n",
      "word 210: .\n",
      "word 211: Softbank\n",
      "word 212: and\n",
      "word 213: Google\n",
      "word 214: are\n",
      "word 215: major\n",
      "word 216: players\n",
      "word 217: .\n"
     ]
    }
   ],
   "source": [
    "wtokens = word_tokenize(rdata)\n",
    "for i , word in enumerate(wtokens):\n",
    "    print(f\"word {i+1}: {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5dc7fc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 1: \n",
      "\n",
      "Word 2: Machine\n",
      "Word 3: learning\n",
      "Word 4: (\n",
      "Word 5: ML\n",
      "Word 6: )\n",
      "Word 7: is\n",
      "Word 8: a\n",
      "Word 9: field\n",
      "Word 10: of\n",
      "Word 11: study\n",
      "Word 12: in\n",
      "Word 13: artificial\n",
      "Word 14: intelligence\n",
      "Word 15: concerned\n",
      "Word 16: with\n",
      "Word 17: the\n",
      "Word 18: development\n",
      "Word 19: of\n",
      "Word 20: computer\n",
      "Word 21: algorithms\n",
      "Word 22: that\n",
      "Word 23: can\n",
      "Word 24: learn\n",
      "Word 25: from\n",
      "Word 26: and\n",
      "Word 27: make\n",
      "Word 28: predictions\n",
      "Word 29: on\n",
      "Word 30: data\n",
      "Word 31: .\n",
      "Word 32: Algorithms\n",
      "Word 33: build\n",
      "Word 34: a\n",
      "Word 35: mathematical\n",
      "Word 36: model\n",
      "Word 37: based\n",
      "Word 38: on\n",
      "Word 39: sample\n",
      "Word 40: data\n",
      "Word 41: ,\n",
      "Word 42: known\n",
      "Word 43: as\n",
      "Word 44: \"\n",
      "Word 45: training\n",
      "Word 46: data\n",
      "Word 47: \"\n",
      "Word 48: ,\n",
      "Word 49: in\n",
      "Word 50: order\n",
      "Word 51: to\n",
      "Word 52: make\n",
      "Word 53: predictions\n",
      "Word 54: or\n",
      "Word 55: decisions\n",
      "Word 56: without\n",
      "Word 57: being\n",
      "Word 58: explicitly\n",
      "Word 59: programmed\n",
      "Word 60: to\n",
      "Word 61: perform\n",
      "Word 62: the\n",
      "Word 63: task\n",
      "Word 64: .\n",
      "Word 65: \n",
      "\n",
      "\n",
      "Word 66: Machine\n",
      "Word 67: learning\n",
      "Word 68: algorithms\n",
      "Word 69: are\n",
      "Word 70: used\n",
      "Word 71: in\n",
      "Word 72: a\n",
      "Word 73: wide\n",
      "Word 74: variety\n",
      "Word 75: of\n",
      "Word 76: applications\n",
      "Word 77: ,\n",
      "Word 78: such\n",
      "Word 79: as\n",
      "Word 80: email\n",
      "Word 81: filtering\n",
      "Word 82: and\n",
      "Word 83: computer\n",
      "Word 84: vision\n",
      "Word 85: ,\n",
      "Word 86: where\n",
      "Word 87: it\n",
      "Word 88: is\n",
      "Word 89: difficult\n",
      "Word 90: or\n",
      "Word 91: infeasible\n",
      "Word 92: to\n",
      "Word 93: develop\n",
      "Word 94: conventional\n",
      "Word 95: algorithms\n",
      "Word 96: to\n",
      "Word 97: perform\n",
      "Word 98: the\n",
      "Word 99: needed\n",
      "Word 100: tasks\n",
      "Word 101: .\n",
      "Word 102: A\n",
      "Word 103: subset\n",
      "Word 104: of\n",
      "Word 105: machine\n",
      "Word 106: learning\n",
      "Word 107: is\n",
      "Word 108: closely\n",
      "Word 109: related\n",
      "Word 110: to\n",
      "Word 111: computational\n",
      "Word 112: statistics\n",
      "Word 113: ,\n",
      "Word 114: which\n",
      "Word 115: focuses\n",
      "Word 116: on\n",
      "Word 117: making\n",
      "Word 118: predictions\n",
      "Word 119: using\n",
      "Word 120: computers\n",
      "Word 121: .\n",
      "Word 122: Mathematical\n",
      "Word 123: optimization\n",
      "Word 124: delivers\n",
      "Word 125: methods\n",
      "Word 126: ,\n",
      "Word 127: theory\n",
      "Word 128: and\n",
      "Word 129: application\n",
      "Word 130: domains\n",
      "Word 131: to\n",
      "Word 132: the\n",
      "Word 133: field\n",
      "Word 134: of\n",
      "Word 135: machine\n",
      "Word 136: learning\n",
      "Word 137: .\n",
      "Word 138: Data\n",
      "Word 139: mining\n",
      "Word 140: is\n",
      "Word 141: a\n",
      "Word 142: related\n",
      "Word 143: field\n",
      "Word 144: of\n",
      "Word 145: study\n",
      "Word 146: ,\n",
      "Word 147: focusing\n",
      "Word 148: on\n",
      "Word 149: exploratory\n",
      "Word 150: data\n",
      "Word 151: analysis\n",
      "Word 152: through\n",
      "Word 153: unsupervised\n",
      "Word 154: learning\n",
      "Word 155: .\n",
      "Word 156: \n",
      "\n",
      "\n",
      "Word 157: In\n",
      "Word 158: its\n",
      "Word 159: application\n",
      "Word 160: across\n",
      "Word 161: business\n",
      "Word 162: problems\n",
      "Word 163: ,\n",
      "Word 164: machine\n",
      "Word 165: learning\n",
      "Word 166: is\n",
      "Word 167: also\n",
      "Word 168: referred\n",
      "Word 169: to\n",
      "Word 170: as\n",
      "Word 171: predictive\n",
      "Word 172: analytics\n",
      "Word 173: .\n",
      "Word 174: \n",
      "\n",
      "\n",
      "Word 175: Machine\n",
      "Word 176: learning\n",
      "Word 177: rocks\n",
      "Word 178: !\n",
      "Word 179: It\n",
      "Word 180: 's\n",
      "Word 181: revolutionizing\n",
      "Word 182: the\n",
      "Word 183: world\n",
      "Word 184: in\n",
      "Word 185: 2023\n",
      "Word 186: (\n",
      "Word 187: and\n",
      "Word 188: beyond\n",
      "Word 189: !\n",
      "Word 190: )\n",
      "Word 191: .\n",
      "Word 192: \n",
      "\n",
      "Word 193: Visit\n",
      "Word 194: our\n",
      "Word 195: site\n",
      "Word 196: :\n",
      "Word 197: http://example.com\n",
      "Word 198: for\n",
      "Word 199: more\n",
      "Word 200: info\n",
      "Word 201: .\n",
      "Word 202: \n",
      "\n",
      "Word 203: This\n",
      "Word 204: is\n",
      "Word 205: awesome\n",
      "Word 206: !\n",
      "Word 207: !\n",
      "Word 208: !\n",
      "Word 209: We\n",
      "Word 210: collected\n",
      "Word 211: 1,234\n",
      "Word 212: data\n",
      "Word 213: points\n",
      "Word 214: .\n",
      "Word 215: \n",
      "\n",
      "Word 216: Softbank\n",
      "Word 217: and\n",
      "Word 218: Google\n",
      "Word 219: are\n",
      "Word 220: major\n",
      "Word 221: players\n",
      "Word 222: .\n",
      "Word 223: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tokenize using spacy:\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "doc = nlp(rdata)\n",
    "for i , word in enumerate(doc):\n",
    "    print(f\"Word {i+1}: {word.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "412637c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: \n",
      "Machine learning (ML) is a field of study in artificial intelligence concerned with the development of computer algorithms that can learn from and make predictions on data.\n",
      "Sentence 2: Algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task.\n",
      "\n",
      "\n",
      "Sentence 3: Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop conventional algorithms to perform the needed tasks.\n",
      "Sentence 4: A subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers.\n",
      "Sentence 5: Mathematical optimization delivers methods, theory and application domains to the field of machine learning.\n",
      "Sentence 6: Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning.\n",
      "\n",
      "\n",
      "Sentence 7: In its application across business problems, machine learning is also referred to as predictive analytics.\n",
      "\n",
      "\n",
      "Sentence 8: Machine learning rocks!\n",
      "Sentence 9: It's revolutionizing the world in 2023 (and beyond!).\n",
      "\n",
      "Sentence 10: Visit our site: http://example.com for more info.\n",
      "\n",
      "Sentence 11: This is awesome!!!\n",
      "Sentence 12: We collected 1,234 data points.\n",
      "\n",
      "Sentence 13: Softbank and Google are major players.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i , sent in enumerate(doc.sents):\n",
    "    print(f\"Sentence {i+1}: {sent.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ccaecb",
   "metadata": {},
   "source": [
    "## Stop word removal:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bba476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machine',\n",
       " 'learning',\n",
       " 'ml',\n",
       " 'field',\n",
       " 'study',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'concerned',\n",
       " 'development',\n",
       " 'computer',\n",
       " 'algorithms',\n",
       " 'learn',\n",
       " 'make',\n",
       " 'predictions',\n",
       " 'data',\n",
       " 'algorithms',\n",
       " 'build',\n",
       " 'mathematical',\n",
       " 'model',\n",
       " 'based',\n",
       " 'sample',\n",
       " 'data',\n",
       " 'known',\n",
       " 'training',\n",
       " 'data',\n",
       " 'order',\n",
       " 'make',\n",
       " 'predictions',\n",
       " 'decisions',\n",
       " 'without',\n",
       " 'explicitly',\n",
       " 'programmed',\n",
       " 'perform',\n",
       " 'task',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'algorithms',\n",
       " 'used',\n",
       " 'wide',\n",
       " 'variety',\n",
       " 'applications',\n",
       " 'email',\n",
       " 'filtering',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'difficult',\n",
       " 'infeasible',\n",
       " 'develop',\n",
       " 'conventional',\n",
       " 'algorithms',\n",
       " 'perform',\n",
       " 'needed',\n",
       " 'tasks',\n",
       " 'subset',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'closely',\n",
       " 'related',\n",
       " 'computational',\n",
       " 'statistics',\n",
       " 'focuses',\n",
       " 'making',\n",
       " 'predictions',\n",
       " 'using',\n",
       " 'computers',\n",
       " 'mathematical',\n",
       " 'optimization',\n",
       " 'delivers',\n",
       " 'methods',\n",
       " 'theory',\n",
       " 'application',\n",
       " 'domains',\n",
       " 'field',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'data',\n",
       " 'mining',\n",
       " 'related',\n",
       " 'field',\n",
       " 'study',\n",
       " 'focusing',\n",
       " 'exploratory',\n",
       " 'data',\n",
       " 'analysis',\n",
       " 'unsupervised',\n",
       " 'learning',\n",
       " 'application',\n",
       " 'across',\n",
       " 'business',\n",
       " 'problems',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'also',\n",
       " 'referred',\n",
       " 'predictive',\n",
       " 'analytics',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'rocks',\n",
       " 'revolutionizing',\n",
       " 'world',\n",
       " 'beyond',\n",
       " 'visit',\n",
       " 'site',\n",
       " 'info',\n",
       " 'awesome',\n",
       " 'collected',\n",
       " 'data',\n",
       " 'points',\n",
       " 'softbank',\n",
       " 'google',\n",
       " 'major',\n",
       " 'players']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sswords = set(stopwords.words('english'))\n",
    "swords = [word for word in word_tokenize(cdata) if word not in sswords]\n",
    "swords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c82791a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[,\n",
       " Machine,\n",
       " learning,\n",
       " (,\n",
       " ML,\n",
       " ),\n",
       " field,\n",
       " study,\n",
       " artificial,\n",
       " intelligence,\n",
       " concerned,\n",
       " development,\n",
       " computer,\n",
       " algorithms,\n",
       " learn,\n",
       " predictions,\n",
       " data,\n",
       " .,\n",
       " Algorithms,\n",
       " build,\n",
       " mathematical,\n",
       " model,\n",
       " based,\n",
       " sample,\n",
       " data,\n",
       " ,,\n",
       " known,\n",
       " \",\n",
       " training,\n",
       " data,\n",
       " \",\n",
       " ,,\n",
       " order,\n",
       " predictions,\n",
       " decisions,\n",
       " explicitly,\n",
       " programmed,\n",
       " perform,\n",
       " task,\n",
       " .,\n",
       " \n",
       " ,\n",
       " Machine,\n",
       " learning,\n",
       " algorithms,\n",
       " wide,\n",
       " variety,\n",
       " applications,\n",
       " ,,\n",
       " email,\n",
       " filtering,\n",
       " computer,\n",
       " vision,\n",
       " ,,\n",
       " difficult,\n",
       " infeasible,\n",
       " develop,\n",
       " conventional,\n",
       " algorithms,\n",
       " perform,\n",
       " needed,\n",
       " tasks,\n",
       " .,\n",
       " subset,\n",
       " machine,\n",
       " learning,\n",
       " closely,\n",
       " related,\n",
       " computational,\n",
       " statistics,\n",
       " ,,\n",
       " focuses,\n",
       " making,\n",
       " predictions,\n",
       " computers,\n",
       " .,\n",
       " Mathematical,\n",
       " optimization,\n",
       " delivers,\n",
       " methods,\n",
       " ,,\n",
       " theory,\n",
       " application,\n",
       " domains,\n",
       " field,\n",
       " machine,\n",
       " learning,\n",
       " .,\n",
       " Data,\n",
       " mining,\n",
       " related,\n",
       " field,\n",
       " study,\n",
       " ,,\n",
       " focusing,\n",
       " exploratory,\n",
       " data,\n",
       " analysis,\n",
       " unsupervised,\n",
       " learning,\n",
       " .,\n",
       " \n",
       " ,\n",
       " application,\n",
       " business,\n",
       " problems,\n",
       " ,,\n",
       " machine,\n",
       " learning,\n",
       " referred,\n",
       " predictive,\n",
       " analytics,\n",
       " .,\n",
       " \n",
       " ,\n",
       " Machine,\n",
       " learning,\n",
       " rocks,\n",
       " !,\n",
       " revolutionizing,\n",
       " world,\n",
       " 2023,\n",
       " (,\n",
       " !,\n",
       " ),\n",
       " .,\n",
       " ,\n",
       " Visit,\n",
       " site,\n",
       " :,\n",
       " http://example.com,\n",
       " info,\n",
       " .,\n",
       " ,\n",
       " awesome,\n",
       " !,\n",
       " !,\n",
       " !,\n",
       " collected,\n",
       " 1,234,\n",
       " data,\n",
       " points,\n",
       " .,\n",
       " ,\n",
       " Softbank,\n",
       " Google,\n",
       " major,\n",
       " players,\n",
       " .,\n",
       " ]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stop word removal using spacy:\n",
    "[word for word in doc if not word.is_stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf9d4b4",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatization:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd7f187",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cc96a340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machin , machine\n",
      "learn , learning\n",
      "ml , ml\n",
      "field , field\n",
      "studi , study\n",
      "artifici , artificial\n",
      "intellig , intelligence\n",
      "concern , concerned\n",
      "develop , development\n",
      "comput , computer\n",
      "algorithm , algorithm\n",
      "learn , learn\n",
      "make , make\n",
      "predict , prediction\n",
      "data , data\n",
      "algorithm , algorithm\n",
      "build , build\n",
      "mathemat , mathematical\n",
      "model , model\n",
      "base , based\n",
      "sampl , sample\n",
      "data , data\n",
      "known , known\n",
      "train , training\n",
      "data , data\n",
      "order , order\n",
      "make , make\n",
      "predict , prediction\n",
      "decis , decision\n",
      "without , without\n",
      "explicitli , explicitly\n",
      "program , programmed\n",
      "perform , perform\n",
      "task , task\n",
      "machin , machine\n",
      "learn , learning\n",
      "algorithm , algorithm\n",
      "use , used\n",
      "wide , wide\n",
      "varieti , variety\n",
      "applic , application\n",
      "email , email\n",
      "filter , filtering\n",
      "comput , computer\n",
      "vision , vision\n",
      "difficult , difficult\n",
      "infeas , infeasible\n",
      "develop , develop\n",
      "convent , conventional\n",
      "algorithm , algorithm\n",
      "perform , perform\n",
      "need , needed\n",
      "task , task\n",
      "subset , subset\n",
      "machin , machine\n",
      "learn , learning\n",
      "close , closely\n",
      "relat , related\n",
      "comput , computational\n",
      "statist , statistic\n",
      "focus , focus\n",
      "make , making\n",
      "predict , prediction\n",
      "use , using\n",
      "comput , computer\n",
      "mathemat , mathematical\n",
      "optim , optimization\n",
      "deliv , delivers\n",
      "method , method\n",
      "theori , theory\n",
      "applic , application\n",
      "domain , domain\n",
      "field , field\n",
      "machin , machine\n",
      "learn , learning\n",
      "data , data\n",
      "mine , mining\n",
      "relat , related\n",
      "field , field\n",
      "studi , study\n",
      "focus , focusing\n",
      "exploratori , exploratory\n",
      "data , data\n",
      "analysi , analysis\n",
      "unsupervis , unsupervised\n",
      "learn , learning\n",
      "applic , application\n",
      "across , across\n",
      "busi , business\n",
      "problem , problem\n",
      "machin , machine\n",
      "learn , learning\n",
      "also , also\n",
      "refer , referred\n",
      "predict , predictive\n",
      "analyt , analytics\n",
      "machin , machine\n",
      "learn , learning\n",
      "rock , rock\n",
      "revolution , revolutionizing\n",
      "world , world\n",
      "beyond , beyond\n",
      "visit , visit\n",
      "site , site\n",
      "info , info\n",
      "awesom , awesome\n",
      "collect , collected\n",
      "data , data\n",
      "point , point\n",
      "softbank , softbank\n",
      "googl , google\n",
      "major , major\n",
      "player , player\n"
     ]
    }
   ],
   "source": [
    "#using nltk\n",
    "from nltk.stem import PorterStemmer , WordNetLemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmed_words = [stemmer.stem(word) for word in swords]\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in swords]\n",
    "for sem , lem in zip(stemmed_words , lemmatized_words):\n",
    "    print(f\"{sem} , {lem}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1e9869c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " 'Machine',\n",
       " 'learning',\n",
       " '(',\n",
       " 'ML',\n",
       " ')',\n",
       " 'be',\n",
       " 'a',\n",
       " 'field',\n",
       " 'of',\n",
       " 'study',\n",
       " 'in',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'concern',\n",
       " 'with',\n",
       " 'the',\n",
       " 'development',\n",
       " 'of',\n",
       " 'computer',\n",
       " 'algorithm',\n",
       " 'that',\n",
       " 'can',\n",
       " 'learn',\n",
       " 'from',\n",
       " 'and',\n",
       " 'make',\n",
       " 'prediction',\n",
       " 'on',\n",
       " 'datum',\n",
       " '.',\n",
       " 'algorithm',\n",
       " 'build',\n",
       " 'a',\n",
       " 'mathematical',\n",
       " 'model',\n",
       " 'base',\n",
       " 'on',\n",
       " 'sample',\n",
       " 'datum',\n",
       " ',',\n",
       " 'know',\n",
       " 'as',\n",
       " '\"',\n",
       " 'training',\n",
       " 'datum',\n",
       " '\"',\n",
       " ',',\n",
       " 'in',\n",
       " 'order',\n",
       " 'to',\n",
       " 'make',\n",
       " 'prediction',\n",
       " 'or',\n",
       " 'decision',\n",
       " 'without',\n",
       " 'be',\n",
       " 'explicitly',\n",
       " 'program',\n",
       " 'to',\n",
       " 'perform',\n",
       " 'the',\n",
       " 'task',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'Machine',\n",
       " 'learning',\n",
       " 'algorithm',\n",
       " 'be',\n",
       " 'use',\n",
       " 'in',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'variety',\n",
       " 'of',\n",
       " 'application',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'email',\n",
       " 'filtering',\n",
       " 'and',\n",
       " 'computer',\n",
       " 'vision',\n",
       " ',',\n",
       " 'where',\n",
       " 'it',\n",
       " 'be',\n",
       " 'difficult',\n",
       " 'or',\n",
       " 'infeasible',\n",
       " 'to',\n",
       " 'develop',\n",
       " 'conventional',\n",
       " 'algorithm',\n",
       " 'to',\n",
       " 'perform',\n",
       " 'the',\n",
       " 'need',\n",
       " 'task',\n",
       " '.',\n",
       " 'a',\n",
       " 'subset',\n",
       " 'of',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'be',\n",
       " 'closely',\n",
       " 'relate',\n",
       " 'to',\n",
       " 'computational',\n",
       " 'statistic',\n",
       " ',',\n",
       " 'which',\n",
       " 'focus',\n",
       " 'on',\n",
       " 'make',\n",
       " 'prediction',\n",
       " 'use',\n",
       " 'computer',\n",
       " '.',\n",
       " 'mathematical',\n",
       " 'optimization',\n",
       " 'deliver',\n",
       " 'method',\n",
       " ',',\n",
       " 'theory',\n",
       " 'and',\n",
       " 'application',\n",
       " 'domain',\n",
       " 'to',\n",
       " 'the',\n",
       " 'field',\n",
       " 'of',\n",
       " 'machine',\n",
       " 'learning',\n",
       " '.',\n",
       " 'data',\n",
       " 'mining',\n",
       " 'be',\n",
       " 'a',\n",
       " 'related',\n",
       " 'field',\n",
       " 'of',\n",
       " 'study',\n",
       " ',',\n",
       " 'focus',\n",
       " 'on',\n",
       " 'exploratory',\n",
       " 'datum',\n",
       " 'analysis',\n",
       " 'through',\n",
       " 'unsupervised',\n",
       " 'learning',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'in',\n",
       " 'its',\n",
       " 'application',\n",
       " 'across',\n",
       " 'business',\n",
       " 'problem',\n",
       " ',',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'be',\n",
       " 'also',\n",
       " 'refer',\n",
       " 'to',\n",
       " 'as',\n",
       " 'predictive',\n",
       " 'analytic',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'Machine',\n",
       " 'learn',\n",
       " 'rock',\n",
       " '!',\n",
       " 'it',\n",
       " 'be',\n",
       " 'revolutionize',\n",
       " 'the',\n",
       " 'world',\n",
       " 'in',\n",
       " '2023',\n",
       " '(',\n",
       " 'and',\n",
       " 'beyond',\n",
       " '!',\n",
       " ')',\n",
       " '.',\n",
       " '\\n',\n",
       " 'visit',\n",
       " 'our',\n",
       " 'site',\n",
       " ':',\n",
       " 'http://example.com',\n",
       " 'for',\n",
       " 'more',\n",
       " 'info',\n",
       " '.',\n",
       " '\\n',\n",
       " 'this',\n",
       " 'be',\n",
       " 'awesome',\n",
       " '!',\n",
       " '!',\n",
       " '!',\n",
       " 'we',\n",
       " 'collect',\n",
       " '1,234',\n",
       " 'datum',\n",
       " 'point',\n",
       " '.',\n",
       " '\\n',\n",
       " 'Softbank',\n",
       " 'and',\n",
       " 'Google',\n",
       " 'be',\n",
       " 'major',\n",
       " 'player',\n",
       " '.',\n",
       " '\\n']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using spacy:\n",
    "# spacy has no stemmer:\n",
    "\n",
    "sstemmed_words = [stemmer.stem(word.text) for word in doc]\n",
    "slemmatized_words = [word.lemma_ for word in doc]\n",
    "slemmatized_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9928199a",
   "metadata": {},
   "source": [
    "# Bag O Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3d83e973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Texts:\n",
      "1: machine learn rock revolutionize world beyond visit site info\n",
      "2: awesome collect datum point\n",
      "3: softbank google major player\n",
      "4: predictive analytic use machine learn solve business problem\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Sample noisy texts\n",
    "\n",
    "texts = [\n",
    "\"Machine learning rocks! It's revolutionizing the world in 2023 (and beyond!). Visit our site: http://example.com for more info.\",\n",
    "\"This is awesome!!! We collected 1,234 data points.\",\n",
    "\"Softbank and Google are major players.\",\n",
    "\"Predictive analytics uses machine learning to solve business problems.\",\n",
    "]\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text): # Lowercase\n",
    "    text = text.lower() # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text) # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text) # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Process text with SpaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Lemmatization + remove stopwords + tokens length > 1 (to skip leftover punct or spaces)\n",
    "    tokens = [token.lemma_ for token in doc if token.text not in stop_words and len(token.text) > 1]\n",
    "\n",
    "    # Join back to string\n",
    "    cleaned_text = \" \".join(tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "cleaned_texts = [clean_text(text) for text in texts]\n",
    "\n",
    "print(\"Cleaned Texts:\")\n",
    "for i, txt in enumerate(cleaned_texts, 1):\n",
    "    print(f\"{i}: {txt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "609fbace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analytic</th>\n",
       "      <th>awesome</th>\n",
       "      <th>beyond</th>\n",
       "      <th>business</th>\n",
       "      <th>collect</th>\n",
       "      <th>datum</th>\n",
       "      <th>google</th>\n",
       "      <th>info</th>\n",
       "      <th>learn</th>\n",
       "      <th>machine</th>\n",
       "      <th>major</th>\n",
       "      <th>player</th>\n",
       "      <th>point</th>\n",
       "      <th>predictive</th>\n",
       "      <th>problem</th>\n",
       "      <th>revolutionize</th>\n",
       "      <th>rock</th>\n",
       "      <th>site</th>\n",
       "      <th>softbank</th>\n",
       "      <th>solve</th>\n",
       "      <th>use</th>\n",
       "      <th>visit</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       analytic  awesome  beyond  business  ...  solve  use  visit  world\n",
       "doc_1         0        0       1         0  ...      0    0      1      1\n",
       "doc_2         0        1       0         0  ...      0    0      0      0\n",
       "doc_3         0        0       0         0  ...      0    0      0      0\n",
       "doc_4         1        0       0         1  ...      1    1      0      0\n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvectorizer = CountVectorizer()\n",
    "bogmat = cvectorizer.fit_transform(cleaned_texts)\n",
    "df = pd.DataFrame(bogmat.toarray() , columns = cvectorizer.get_feature_names_out())\n",
    "df.index = [f\"doc_{i+1}\" for i in range(len(cleaned_texts))]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfa6893",
   "metadata": {},
   "source": [
    "## TFIDF implementation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "70dbcffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analytic</th>\n",
       "      <th>awesome</th>\n",
       "      <th>beyond</th>\n",
       "      <th>business</th>\n",
       "      <th>collect</th>\n",
       "      <th>datum</th>\n",
       "      <th>google</th>\n",
       "      <th>info</th>\n",
       "      <th>learn</th>\n",
       "      <th>machine</th>\n",
       "      <th>major</th>\n",
       "      <th>player</th>\n",
       "      <th>point</th>\n",
       "      <th>predictive</th>\n",
       "      <th>problem</th>\n",
       "      <th>revolutionize</th>\n",
       "      <th>rock</th>\n",
       "      <th>site</th>\n",
       "      <th>softbank</th>\n",
       "      <th>solve</th>\n",
       "      <th>use</th>\n",
       "      <th>visit</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc_1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.348299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.348299</td>\n",
       "      <td>0.274603</td>\n",
       "      <td>0.274603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.348299</td>\n",
       "      <td>0.348299</td>\n",
       "      <td>0.348299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.348299</td>\n",
       "      <td>0.348299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_4</th>\n",
       "      <td>0.371565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292946</td>\n",
       "      <td>0.292946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371565</td>\n",
       "      <td>0.371565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371565</td>\n",
       "      <td>0.371565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       analytic  awesome    beyond  ...       use     visit     world\n",
       "doc_1  0.000000      0.0  0.348299  ...  0.000000  0.348299  0.348299\n",
       "doc_2  0.000000      0.5  0.000000  ...  0.000000  0.000000  0.000000\n",
       "doc_3  0.000000      0.0  0.000000  ...  0.000000  0.000000  0.000000\n",
       "doc_4  0.371565      0.0  0.000000  ...  0.371565  0.000000  0.000000\n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvectorizer = TfidfVectorizer()\n",
    "tmat = tvectorizer.fit_transform(cleaned_texts)\n",
    "pd.DataFrame(tmat.toarray() , columns = tvectorizer.get_feature_names_out() , index = [f\"doc_{i+1}\" for i in range(len(cleaned_texts))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467d74a9",
   "metadata": {},
   "source": [
    "## POS tagging:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "103722fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n -> (SPACE , _SP)',\n",
       " 'Machine -> (PROPN , NNP)',\n",
       " 'learning -> (NOUN , NN)',\n",
       " '( -> (PUNCT , -LRB-)',\n",
       " 'ML -> (PROPN , NNP)',\n",
       " ') -> (PUNCT , -RRB-)',\n",
       " 'is -> (AUX , VBZ)',\n",
       " 'a -> (DET , DT)',\n",
       " 'field -> (NOUN , NN)',\n",
       " 'of -> (ADP , IN)',\n",
       " 'study -> (NOUN , NN)',\n",
       " 'in -> (ADP , IN)',\n",
       " 'artificial -> (ADJ , JJ)',\n",
       " 'intelligence -> (NOUN , NN)',\n",
       " 'concerned -> (VERB , VBN)',\n",
       " 'with -> (ADP , IN)',\n",
       " 'the -> (DET , DT)',\n",
       " 'development -> (NOUN , NN)',\n",
       " 'of -> (ADP , IN)',\n",
       " 'computer -> (NOUN , NN)',\n",
       " 'algorithms -> (NOUN , NNS)',\n",
       " 'that -> (PRON , WDT)',\n",
       " 'can -> (AUX , MD)',\n",
       " 'learn -> (VERB , VB)',\n",
       " 'from -> (ADP , IN)',\n",
       " 'and -> (CCONJ , CC)',\n",
       " 'make -> (VERB , VB)',\n",
       " 'predictions -> (NOUN , NNS)',\n",
       " 'on -> (ADP , IN)',\n",
       " 'data -> (NOUN , NNS)',\n",
       " '. -> (PUNCT , .)',\n",
       " 'Algorithms -> (NOUN , NNS)',\n",
       " 'build -> (VERB , VBP)',\n",
       " 'a -> (DET , DT)',\n",
       " 'mathematical -> (ADJ , JJ)',\n",
       " 'model -> (NOUN , NN)',\n",
       " 'based -> (VERB , VBN)',\n",
       " 'on -> (ADP , IN)',\n",
       " 'sample -> (NOUN , NN)',\n",
       " 'data -> (NOUN , NNS)',\n",
       " ', -> (PUNCT , ,)',\n",
       " 'known -> (VERB , VBN)',\n",
       " 'as -> (ADP , IN)',\n",
       " '\" -> (PUNCT , ``)',\n",
       " 'training -> (NOUN , NN)',\n",
       " 'data -> (NOUN , NNS)',\n",
       " '\" -> (PUNCT , \\'\\')',\n",
       " ', -> (PUNCT , ,)',\n",
       " 'in -> (ADP , IN)',\n",
       " 'order -> (NOUN , NN)',\n",
       " 'to -> (PART , TO)',\n",
       " 'make -> (VERB , VB)',\n",
       " 'predictions -> (NOUN , NNS)',\n",
       " 'or -> (CCONJ , CC)',\n",
       " 'decisions -> (NOUN , NNS)',\n",
       " 'without -> (ADP , IN)',\n",
       " 'being -> (AUX , VBG)',\n",
       " 'explicitly -> (ADV , RB)',\n",
       " 'programmed -> (VERB , VBN)',\n",
       " 'to -> (PART , TO)',\n",
       " 'perform -> (VERB , VB)',\n",
       " 'the -> (DET , DT)',\n",
       " 'task -> (NOUN , NN)',\n",
       " '. -> (PUNCT , .)',\n",
       " '\\n\\n -> (SPACE , _SP)',\n",
       " 'Machine -> (PROPN , NNP)',\n",
       " 'learning -> (NOUN , NN)',\n",
       " 'algorithms -> (NOUN , NNS)',\n",
       " 'are -> (AUX , VBP)',\n",
       " 'used -> (VERB , VBN)',\n",
       " 'in -> (ADP , IN)',\n",
       " 'a -> (DET , DT)',\n",
       " 'wide -> (ADJ , JJ)',\n",
       " 'variety -> (NOUN , NN)',\n",
       " 'of -> (ADP , IN)',\n",
       " 'applications -> (NOUN , NNS)',\n",
       " ', -> (PUNCT , ,)',\n",
       " 'such -> (ADJ , JJ)',\n",
       " 'as -> (ADP , IN)',\n",
       " 'email -> (NOUN , NN)',\n",
       " 'filtering -> (NOUN , NN)',\n",
       " 'and -> (CCONJ , CC)',\n",
       " 'computer -> (NOUN , NN)',\n",
       " 'vision -> (NOUN , NN)',\n",
       " ', -> (PUNCT , ,)',\n",
       " 'where -> (SCONJ , WRB)',\n",
       " 'it -> (PRON , PRP)',\n",
       " 'is -> (AUX , VBZ)',\n",
       " 'difficult -> (ADJ , JJ)',\n",
       " 'or -> (CCONJ , CC)',\n",
       " 'infeasible -> (ADJ , JJ)',\n",
       " 'to -> (PART , TO)',\n",
       " 'develop -> (VERB , VB)',\n",
       " 'conventional -> (ADJ , JJ)',\n",
       " 'algorithms -> (NOUN , NNS)',\n",
       " 'to -> (PART , TO)',\n",
       " 'perform -> (VERB , VB)',\n",
       " 'the -> (DET , DT)',\n",
       " 'needed -> (VERB , VBN)',\n",
       " 'tasks -> (NOUN , NNS)',\n",
       " '. -> (PUNCT , .)',\n",
       " 'A -> (DET , DT)',\n",
       " 'subset -> (NOUN , NN)',\n",
       " 'of -> (ADP , IN)',\n",
       " 'machine -> (NOUN , NN)',\n",
       " 'learning -> (NOUN , NN)',\n",
       " 'is -> (AUX , VBZ)',\n",
       " 'closely -> (ADV , RB)',\n",
       " 'related -> (VERB , VBN)',\n",
       " 'to -> (ADP , IN)',\n",
       " 'computational -> (ADJ , JJ)',\n",
       " 'statistics -> (NOUN , NNS)',\n",
       " ', -> (PUNCT , ,)',\n",
       " 'which -> (PRON , WDT)',\n",
       " 'focuses -> (VERB , VBZ)',\n",
       " 'on -> (ADP , IN)',\n",
       " 'making -> (VERB , VBG)',\n",
       " 'predictions -> (NOUN , NNS)',\n",
       " 'using -> (VERB , VBG)',\n",
       " 'computers -> (NOUN , NNS)',\n",
       " '. -> (PUNCT , .)',\n",
       " 'Mathematical -> (ADJ , JJ)',\n",
       " 'optimization -> (NOUN , NN)',\n",
       " 'delivers -> (VERB , VBZ)',\n",
       " 'methods -> (NOUN , NNS)',\n",
       " ', -> (PUNCT , ,)',\n",
       " 'theory -> (NOUN , NN)',\n",
       " 'and -> (CCONJ , CC)',\n",
       " 'application -> (NOUN , NN)',\n",
       " 'domains -> (NOUN , NNS)',\n",
       " 'to -> (ADP , IN)',\n",
       " 'the -> (DET , DT)',\n",
       " 'field -> (NOUN , NN)',\n",
       " 'of -> (ADP , IN)',\n",
       " 'machine -> (NOUN , NN)',\n",
       " 'learning -> (NOUN , NN)',\n",
       " '. -> (PUNCT , .)',\n",
       " 'Data -> (NOUN , NN)',\n",
       " 'mining -> (NOUN , NN)',\n",
       " 'is -> (AUX , VBZ)',\n",
       " 'a -> (DET , DT)',\n",
       " 'related -> (ADJ , JJ)',\n",
       " 'field -> (NOUN , NN)',\n",
       " 'of -> (ADP , IN)',\n",
       " 'study -> (NOUN , NN)',\n",
       " ', -> (PUNCT , ,)',\n",
       " 'focusing -> (VERB , VBG)',\n",
       " 'on -> (ADP , IN)',\n",
       " 'exploratory -> (ADJ , JJ)',\n",
       " 'data -> (NOUN , NNS)',\n",
       " 'analysis -> (NOUN , NN)',\n",
       " 'through -> (ADP , IN)',\n",
       " 'unsupervised -> (ADJ , JJ)',\n",
       " 'learning -> (NOUN , NN)',\n",
       " '. -> (PUNCT , .)',\n",
       " '\\n\\n -> (SPACE , _SP)',\n",
       " 'In -> (ADP , IN)',\n",
       " 'its -> (PRON , PRP$)',\n",
       " 'application -> (NOUN , NN)',\n",
       " 'across -> (ADP , IN)',\n",
       " 'business -> (NOUN , NN)',\n",
       " 'problems -> (NOUN , NNS)',\n",
       " ', -> (PUNCT , ,)',\n",
       " 'machine -> (NOUN , NN)',\n",
       " 'learning -> (NOUN , NN)',\n",
       " 'is -> (AUX , VBZ)',\n",
       " 'also -> (ADV , RB)',\n",
       " 'referred -> (VERB , VBN)',\n",
       " 'to -> (ADP , IN)',\n",
       " 'as -> (ADP , IN)',\n",
       " 'predictive -> (ADJ , JJ)',\n",
       " 'analytics -> (NOUN , NNS)',\n",
       " '. -> (PUNCT , .)',\n",
       " '\\n\\n -> (SPACE , _SP)',\n",
       " 'Machine -> (PROPN , NNP)',\n",
       " 'learning -> (VERB , VBG)',\n",
       " 'rocks -> (NOUN , NNS)',\n",
       " '! -> (PUNCT , .)',\n",
       " 'It -> (PRON , PRP)',\n",
       " \"'s -> (AUX , VBZ)\",\n",
       " 'revolutionizing -> (VERB , VBG)',\n",
       " 'the -> (DET , DT)',\n",
       " 'world -> (NOUN , NN)',\n",
       " 'in -> (ADP , IN)',\n",
       " '2023 -> (NUM , CD)',\n",
       " '( -> (PUNCT , -LRB-)',\n",
       " 'and -> (CCONJ , CC)',\n",
       " 'beyond -> (ADP , IN)',\n",
       " '! -> (PUNCT , .)',\n",
       " ') -> (PUNCT , -RRB-)',\n",
       " '. -> (PUNCT , .)',\n",
       " '\\n -> (SPACE , _SP)',\n",
       " 'Visit -> (VERB , VB)',\n",
       " 'our -> (PRON , PRP$)',\n",
       " 'site -> (NOUN , NN)',\n",
       " ': -> (PUNCT , :)',\n",
       " 'http://example.com -> (X , ADD)',\n",
       " 'for -> (ADP , IN)',\n",
       " 'more -> (ADJ , JJR)',\n",
       " 'info -> (NOUN , NN)',\n",
       " '. -> (PUNCT , .)',\n",
       " '\\n -> (SPACE , _SP)',\n",
       " 'This -> (PRON , DT)',\n",
       " 'is -> (AUX , VBZ)',\n",
       " 'awesome -> (ADJ , JJ)',\n",
       " '! -> (PUNCT , .)',\n",
       " '! -> (PUNCT , .)',\n",
       " '! -> (PUNCT , .)',\n",
       " 'We -> (PRON , PRP)',\n",
       " 'collected -> (VERB , VBD)',\n",
       " '1,234 -> (NUM , CD)',\n",
       " 'data -> (NOUN , NNS)',\n",
       " 'points -> (NOUN , NNS)',\n",
       " '. -> (PUNCT , .)',\n",
       " '\\n -> (SPACE , _SP)',\n",
       " 'Softbank -> (PROPN , NNP)',\n",
       " 'and -> (CCONJ , CC)',\n",
       " 'Google -> (PROPN , NNP)',\n",
       " 'are -> (AUX , VBP)',\n",
       " 'major -> (ADJ , JJ)',\n",
       " 'players -> (NOUN , NNS)',\n",
       " '. -> (PUNCT , .)',\n",
       " '\\n -> (SPACE , _SP)']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"{word} -> ({word.pos_} , {word.tag_})\"for word in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd0c621",
   "metadata": {},
   "source": [
    "# Sentiment Analysis:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "99ce8960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from nrclex import NRCLex\n",
    "from afinn import Afinn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "192d24e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Place</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>status</th>\n",
       "      <th>job_title</th>\n",
       "      <th>summary</th>\n",
       "      <th>positives</th>\n",
       "      <th>negatives</th>\n",
       "      <th>advice_to_mgmt</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>score_3</th>\n",
       "      <th>score_4</th>\n",
       "      <th>score_5</th>\n",
       "      <th>score_6</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>startup_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dec 11, 2018</td>\n",
       "      <td>Current Employee</td>\n",
       "      <td>Anonymous Employee</td>\n",
       "      <td>Best Company to work for</td>\n",
       "      <td>People are smart and friendly</td>\n",
       "      <td>Bureaucracy is slowing things down</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>startup_1</td>\n",
       "      <td>Mountain View, CA</td>\n",
       "      <td>Jun 21, 2013</td>\n",
       "      <td>Former Employee</td>\n",
       "      <td>Program Manager</td>\n",
       "      <td>Moving at the speed of light, burn out is inev...</td>\n",
       "      <td>1) Food, food, food. 15+ cafes on main campus ...</td>\n",
       "      <td>1) Work/life balance. What balance? All those ...</td>\n",
       "      <td>1) Don't dismiss emotional intelligence and ad...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2094</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>startup_1</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>May 10, 2014</td>\n",
       "      <td>Current Employee</td>\n",
       "      <td>Software Engineer III</td>\n",
       "      <td>Great balance between big-company security and...</td>\n",
       "      <td>* If you're a software engineer, you're among ...</td>\n",
       "      <td>* It *is* becoming larger, and with it comes g...</td>\n",
       "      <td>Keep the focus on the user. Everything else wi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>949</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>startup_1</td>\n",
       "      <td>Mountain View, CA</td>\n",
       "      <td>Feb 8, 2015</td>\n",
       "      <td>Current Employee</td>\n",
       "      <td>Anonymous Employee</td>\n",
       "      <td>The best place I've worked and also the most d...</td>\n",
       "      <td>You can't find a more well-regarded company th...</td>\n",
       "      <td>I live in SF so the commute can take between 1...</td>\n",
       "      <td>Keep on NOT micromanaging - that is a huge ben...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>498</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>startup_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dec 9, 2018</td>\n",
       "      <td>Current Employee</td>\n",
       "      <td>Anonymous Employee</td>\n",
       "      <td>Execellent for engineers</td>\n",
       "      <td>Impact driven. Best tech in the world.</td>\n",
       "      <td>Size matters. Engineers are a bit disconnected...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID      Place           location  ... score_5 score_6 overall\n",
       "0   1  startup_1                NaN  ...     5.0       0       5\n",
       "1   2  startup_1  Mountain View, CA  ...     3.0    2094       5\n",
       "2   3  startup_1       New York, NY  ...     4.0     949       5\n",
       "3   4  startup_1  Mountain View, CA  ...     5.0     498       4\n",
       "4  10  startup_1                NaN  ...     5.0       0       4\n",
       "\n",
       "[5 rows x 17 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "63d0cb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The money was great and the talent of my peers far exceeded any group I have worked with.',\n",
       " 2401                  good working environment ,culture .\n",
       " 2402    Amazing People Good Benefits Amazing opportuni...\n",
       " 2403                        Awesome working place to work\n",
       " 2404    Google truly stands out when it comes to benef...\n",
       " 2405    Best in the market Good experience Learnt a lo...\n",
       " 2406    Usually engineers can pursue doing the technic...\n",
       " 2407                        worked at school environment\n",
       " Name: positives, dtype: object,\n",
       " 2401                            nothing to say for cons .\n",
       " 2402    Recruitment is horrible, they forget you, and ...\n",
       " 2403       sleepless nights. countless meetings to attend\n",
       " 2404    i am an normal student studying in panimalar e...\n",
       " 2405    Pressurised a little Too far in gurgaon Can be...\n",
       " 2406    A little bit shift from bottom-up to top-down ...\n",
       " 2407                              did not receive salary\n",
       " Name: negatives, dtype: object)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = data['positives'].iloc[9919]\n",
    "psentences = data['positives'].iloc[2401:2408]\n",
    "nsentences = data['negatives'].iloc[2401: 2408]\n",
    "text , psentences  ,nsentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4280f0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.45, 0.875)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(text)\n",
    "blob.sentiment.polarity , blob.sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1e706f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review: nothing to say for cons . \n",
      " polarity: 0.0 \n",
      " ****************************************\n",
      "review: Recruitment is horrible, they forget you, and only care about their own job. People are too educated for their positions. It's very structured compared to what they wish to be. Innovation happens by acquiring start-ups. Internal transfers to other countries can be a lot more difficult than they say. \n",
      " polarity: -0.040625 \n",
      " ****************************************\n",
      "review: sleepless nights. countless meetings to attend \n",
      " polarity: 0.0 \n",
      " ****************************************\n",
      "review: i am an normal student studying in panimalar engineering college (chennai)1 year (ece group) \n",
      " polarity: 0.15 \n",
      " ****************************************\n",
      "review: Pressurised a little Too far in gurgaon Can be hectic for some as its a target based work and can build pressure \n",
      " polarity: -0.04375 \n",
      " ****************************************\n",
      "review: A little bit shift from bottom-up to top-down culture. \n",
      " polarity: -0.1875 \n",
      " ****************************************\n",
      "review:  did not receive salary \n",
      " polarity: 0.0 \n",
      " ****************************************\n"
     ]
    }
   ],
   "source": [
    "for sentence in nsentences:\n",
    "    print(f\"review: {sentence} \\n polarity: {TextBlob(sentence).polarity} \\n\" , \"*\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e39a1ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'anger': 1,\n",
       "  'anticipation': 1,\n",
       "  'joy': 1,\n",
       "  'positive': 2,\n",
       "  'surprise': 1,\n",
       "  'trust': 1},\n",
       " [('positive', 0.2857142857142857)],\n",
       " {'fear': 0.0,\n",
       "  'anger': 0.14285714285714285,\n",
       "  'anticip': 0.0,\n",
       "  'trust': 0.14285714285714285,\n",
       "  'surprise': 0.14285714285714285,\n",
       "  'positive': 0.2857142857142857,\n",
       "  'negative': 0.0,\n",
       "  'sadness': 0.0,\n",
       "  'disgust': 0.0,\n",
       "  'joy': 0.14285714285714285,\n",
       "  'anticipation': 0.14285714285714285})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using nrclex:\n",
    "emotion = NRCLex(text)\n",
    "emotion.raw_emotion_scores , emotion.top_emotions , emotion.affect_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3f09d515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: The movie made me happy, anxious and full of anticipation.\n",
      "            word       emotion  flag\n",
      "0         happy,  anticipation     1\n",
      "1         happy,           joy     1\n",
      "2         happy,      positive     1\n",
      "3         happy,         trust     1\n",
      "4        anxious  anticipation     1\n",
      "5        anxious          fear     1\n",
      "6        anxious      negative     1\n",
      "7           full      positive     1\n",
      "8  anticipation.  anticipation     1\n",
      "emotion        anticipation  fear  joy  negative  positive  trust\n",
      "word                                                             \n",
      "anticipation.           1.0   0.0  0.0       0.0       0.0    0.0\n",
      "anxious                 1.0   1.0  0.0       1.0       0.0    0.0\n",
      "full                    0.0   0.0  0.0       0.0       1.0    0.0\n",
      "happy,                  1.0   0.0  1.0       0.0       1.0    1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emodata = []\n",
    "text = \"The movie made me happy, anxious and full of anticipation.\"\n",
    "print(f\"text: {text}\")\n",
    "words = text.lower().split()\n",
    "\n",
    "for word in words:\n",
    "    emotion = NRCLex(word)\n",
    "    for emo in emotion.raw_emotion_scores.keys():\n",
    "        emodata.append({\"word\":word , \"emotion\" : emo , \"flag\": 1})\n",
    "\n",
    "df = pd.DataFrame(emodata)\n",
    "print(df)\n",
    "ptable = pd.pivot_table(df , values = 'flag' , columns = 'emotion' , index = 'word' , fill_value = 0)\n",
    "print(ptable)\n",
    "\n",
    "sns.heatmap(ptable , cmap = 'Greens' , cbar = False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a3e8e4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The service was amazing and the staff was wonderful! --> 8.0\n",
      "af.score_with_pattern(sentence) = 8.0\n",
      "af.score_with_wordlist(sentence) = 8.0\n",
      "words = ['The', 'service', 'was', 'amazing', 'and', 'the', 'staff', 'was', 'wonderful']\n",
      "matched_words = ['amazing', 'wonderful']\n",
      "word_scores = {'amazing': 4.0, 'wonderful': 4.0}\n",
      "total: 8.0\n",
      "****************************************************************************************************\n",
      "The food was horrible and I hated the experience. --> -6.0\n",
      "af.score_with_pattern(sentence) = -6.0\n",
      "af.score_with_wordlist(sentence) = -6.0\n",
      "words = ['The', 'food', 'was', 'horrible', 'and', 'I', 'hated', 'the', 'experience']\n",
      "matched_words = ['horrible', 'hated']\n",
      "word_scores = {'horrible': -3.0, 'hated': -3.0}\n",
      "total: -6.0\n",
      "****************************************************************************************************\n",
      "The hotel is okay, nothing special. --> 0.0\n",
      "af.score_with_pattern(sentence) = 0.0\n",
      "af.score_with_wordlist(sentence) = 0.0\n",
      "words = ['The', 'hotel', 'is', 'okay', 'nothing', 'special']\n",
      "matched_words = []\n",
      "word_scores = {}\n",
      "total: 0.0\n",
      "****************************************************************************************************\n",
      "Absolutely love this place! --> 3.0\n",
      "af.score_with_pattern(sentence) = 3.0\n",
      "af.score_with_wordlist(sentence) = 3.0\n",
      "words = ['Absolutely', 'love', 'this', 'place']\n",
      "matched_words = ['love']\n",
      "word_scores = {'love': 3.0}\n",
      "total: 3.0\n",
      "****************************************************************************************************\n",
      "The customer support is terrible! --> -1.0\n",
      "af.score_with_pattern(sentence) = -1.0\n",
      "af.score_with_wordlist(sentence) = -1.0\n",
      "words = ['The', 'customer', 'support', 'is', 'terrible']\n",
      "matched_words = ['support', 'terrible']\n",
      "word_scores = {'support': 2.0, 'terrible': -3.0}\n",
      "total: -1.0\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from afinn import Afinn\n",
    "\n",
    "af = Afinn()\n",
    "\n",
    "sentences = [\n",
    "    \"The service was amazing and the staff was wonderful!\",\n",
    "    \"The food was horrible and I hated the experience.\",\n",
    "    \"The hotel is okay, nothing special.\",\n",
    "    \"Absolutely love this place!\",\n",
    "    \"The customer support is terrible!\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(f\"{sentence} --> {af.score(sentence)}\")\n",
    "    print(f\"{af.score_with_pattern(sentence) = }\")\n",
    "    print(f\"{af.score_with_wordlist(sentence) = }\")\n",
    "    #find matched words and print each word's score:\n",
    "    words = af.split(sentence)\n",
    "    print(f\"{words = }\")\n",
    "    matched_words = [word for word in words if af.score(word) != 0]\n",
    "    word_scores = {word : af.score(word) for word in matched_words}\n",
    "    print(f\"{matched_words = }\")\n",
    "    print(f\"{word_scores = }\")\n",
    "    print(f\"total: {af.score(sentence)}\")\n",
    "    print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036bba42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
